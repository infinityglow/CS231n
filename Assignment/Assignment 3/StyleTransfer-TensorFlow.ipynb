{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Transfer\n",
    "In this notebook we will implement the style transfer technique from [\"Image Style Transfer Using Convolutional Neural Networks\" (Gatys et al., CVPR 2015)](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf).\n",
    "\n",
    "The general idea is to take two images, and produce a new image that reflects the content of one but the artistic \"style\" of the other. We will do this by first formulating a loss function that matches the content and style of each respective image in the feature space of a deep network, and then performing gradient descent on the pixels of the image itself.\n",
    "\n",
    "The deep network we use as a feature extractor is [SqueezeNet](https://arxiv.org/abs/1602.07360), a small model that has been trained on ImageNet. You could use any network, but we chose SqueezeNet here for its small size and efficiency.\n",
    "\n",
    "Here's an example of the images you'll be able to produce by the end of this notebook:\n",
    "\n",
    "![caption](example_styletransfer.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from scipy.misc import imread, imresize\n",
    "import numpy as np\n",
    "\n",
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Helper functions to deal with image preprocessing\n",
    "from cs231n.image_utils import load_image, preprocess_image, deprocess_image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def get_session():\n",
    "    \"\"\"Create a session that dynamically allocates memory.\"\"\"\n",
    "    # See: https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "    return session\n",
    "\n",
    "def rel_error(x,y):\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "# Older versions of scipy.misc.imresize yield different results\n",
    "# from newer versions, so we check to make sure scipy is up to date.\n",
    "def check_scipy():\n",
    "    import scipy\n",
    "    vnum = int(scipy.__version__.split('.')[1])\n",
    "    assert vnum >= 16, \"You must install SciPy >= 0.16.0 to complete this notebook.\"\n",
    "\n",
    "# check_scipy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pretrained SqueezeNet model. This model has been ported from PyTorch, see `cs231n/classifiers/squeezenet.py` for the model architecture. \n",
    "\n",
    "To use SqueezeNet, you will need to first **download the weights** by changing into the `cs231n/datasets` directory and running `get_squeezenet_tf.sh` . Note that if you ran `get_assignment3_data.sh` then SqueezeNet will already be downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from cs231n/datasets/squeezenet.ckpt\n",
      "Tensor(\"features_1/layer3/fire/concat:0\", shape=(?, ?, ?, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from cs231n.classifiers.squeezenet import SqueezeNet\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph() # remove all existing variables in the graph \n",
    "sess = get_session() # start a new Session\n",
    "\n",
    "# Load pretrained SqueezeNet model\n",
    "SAVE_PATH = 'cs231n/datasets/squeezenet.ckpt'\n",
    "# if not os.path.exists(SAVE_PATH):\n",
    "#     raise ValueError(\"You need to download SqueezeNet!\")\n",
    "model = SqueezeNet(save_path=SAVE_PATH, sess=sess)\n",
    "\n",
    "# Load data for testing\n",
    "content_img_test = preprocess_image(load_image('styles/tubingen.jpg', size=192))[None]\n",
    "style_img_test = preprocess_image(load_image('styles/starry_night.jpg', size=192))[None]\n",
    "answers = np.load('style-transfer-checks-tf.npz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Loss\n",
    "\n",
    "We're going to compute the three components of our loss function now. The loss function is a weighted sum of three terms: content loss + style loss + total variation loss. You'll fill in the functions that compute these weighted terms below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content loss\n",
    "We can generate an image that reflects the content of one image and the style of another by incorporating both in our loss function. We want to penalize deviations from the content of the content image and deviations from the style of the style image. We can then use this hybrid loss function to perform gradient descent **not on the parameters** of the model, but instead **on the pixel values** of our original image.\n",
    "\n",
    "Let's first write the content loss function. Content loss measures how much the feature map of the generated image differs from the feature map of the source image. We only care about the content representation of one layer of the network (say, layer $\\ell$), that has feature maps $A^\\ell \\in \\mathbb{R}^{1 \\times C_\\ell \\times H_\\ell \\times W_\\ell}$. $C_\\ell$ is the number of filters/channels in layer $\\ell$, $H_\\ell$ and $W_\\ell$ are the height and width. We will work with reshaped versions of these feature maps that combine all spatial positions into one dimension. Let $F^\\ell \\in \\mathbb{R}^{N_\\ell \\times M_\\ell}$ be the feature map for the current image and $P^\\ell \\in \\mathbb{R}^{N_\\ell \\times M_\\ell}$ be the feature map for the content source image where $M_\\ell=H_\\ell\\times W_\\ell$ is the number of elements in each feature map. Each row of $F^\\ell$ or $P^\\ell$ represents the vectorized activations of a particular filter, convolved over all positions of the image. Finally, let $w_c$ be the weight of the content loss term in the loss function.\n",
    "\n",
    "Then the content loss is given by:\n",
    "\n",
    "$L_c = w_c \\times \\sum_{i,j} (F_{ij}^{\\ell} - P_{ij}^{\\ell})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(content_weight, content_current, content_original):\n",
    "    \"\"\"\n",
    "    Compute the content loss for style transfer.\n",
    "    \n",
    "    Inputs:\n",
    "    - content_weight: scalar constant we multiply the content_loss by.\n",
    "    - content_current: features of the current image, Tensor with shape [1, height, width, channels]\n",
    "    - content_target: features of the content image, Tensor with shape [1, height, width, channels]\n",
    "    \n",
    "    Returns:\n",
    "    - scalar content loss\n",
    "    \"\"\"\n",
    "    return content_weight * tf.reduce_sum(tf.square(content_current - content_original))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your content loss. You should see errors less than 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value features/layer3/fire/e11/weights\n\t [[node features/layer3/fire/e11/weights/read (defined at /home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py:13) ]]\n\nCaused by op 'features/layer3/fire/e11/weights/read', defined at:\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-d740efe20a32>\", line 11, in <module>\n    model = SqueezeNet(save_path=SAVE_PATH, sess=sess)\n  File \"/home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py\", line 87, in __init__\n    self.layers = self.extract_features(x, reuse=False)\n  File \"/home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py\", line 45, in extract_features\n    x = fire_module(x,64,16,64,64)\n  File \"/home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py\", line 13, in fire_module\n    W = tf.get_variable(\"weights\",shape=[1,1,sp,e11p])\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1479, in get_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1220, in get_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 547, in get_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 499, in _true_getter\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 911, in _get_single_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1557, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 81, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3890, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value features/layer3/fire/e11/weights\n\t [[node features/layer3/fire/e11/weights/read (defined at /home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py:13) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value features/layer3/fire/e11/weights\n\t [[{{node features/layer3/fire/e11/weights/read}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f6024ff01d4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Maximum error is {:.3f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcontent_loss_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cl_out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-f6024ff01d4f>\u001b[0m in \u001b[0;36mcontent_loss_test\u001b[0;34m(correct)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcontent_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcontent_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6e-2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mc_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontent_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontent_img_test\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mbad_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_img_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontent_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value features/layer3/fire/e11/weights\n\t [[node features/layer3/fire/e11/weights/read (defined at /home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py:13) ]]\n\nCaused by op 'features/layer3/fire/e11/weights/read', defined at:\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-d740efe20a32>\", line 11, in <module>\n    model = SqueezeNet(save_path=SAVE_PATH, sess=sess)\n  File \"/home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py\", line 87, in __init__\n    self.layers = self.extract_features(x, reuse=False)\n  File \"/home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py\", line 45, in extract_features\n    x = fire_module(x,64,16,64,64)\n  File \"/home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py\", line 13, in fire_module\n    W = tf.get_variable(\"weights\",shape=[1,1,sp,e11p])\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1479, in get_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1220, in get_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 547, in get_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 499, in _true_getter\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 911, in _get_single_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1557, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 81, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3890, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value features/layer3/fire/e11/weights\n\t [[node features/layer3/fire/e11/weights/read (defined at /home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py:13) ]]\n"
     ]
    }
   ],
   "source": [
    "def content_loss_test(correct):\n",
    "    content_layer = 3\n",
    "    content_weight = 6e-2\n",
    "    c_feats = sess.run(model.extract_features()[content_layer], {model.image: content_img_test})\n",
    "    bad_img = tf.zeros(content_img_test.shape)\n",
    "    feats = model.extract_features(bad_img)[content_layer]\n",
    "    student_output = sess.run(content_loss(content_weight, c_feats, feats))\n",
    "    error = rel_error(correct, student_output)\n",
    "    print('Maximum error is {:.3f}'.format(error))\n",
    "\n",
    "content_loss_test(answers['cl_out'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style loss\n",
    "Now we can tackle the style loss. For a given layer $\\ell$, the style loss is defined as follows:\n",
    "\n",
    "First, compute the Gram matrix G which represents the correlations between the responses of each filter, where F is as above. The Gram matrix is an approximation to the covariance matrix -- we want the activation statistics of our generated image to match the activation statistics of our style image, and matching the (approximate) covariance is one way to do that. There are a variety of ways you could do this, but the Gram matrix is nice because it's easy to compute and in practice shows good results.\n",
    "\n",
    "Given a feature map $F^\\ell$ of shape $(1, C_\\ell, M_\\ell)$, the Gram matrix has shape $(1, C_\\ell, C_\\ell)$ and its elements are given by:\n",
    "\n",
    "$$G_{ij}^\\ell  = \\sum_k F^{\\ell}_{ik} F^{\\ell}_{jk}$$\n",
    "\n",
    "Assuming $G^\\ell$ is the Gram matrix from the feature map of the current image, $A^\\ell$ is the Gram Matrix from the feature map of the source style image, and $w_\\ell$ a scalar weight term, then the style loss for the layer $\\ell$ is simply the weighted Euclidean distance between the two Gram matrices:\n",
    "\n",
    "$$L_s^\\ell = w_\\ell \\sum_{i, j} \\left(G^\\ell_{ij} - A^\\ell_{ij}\\right)^2$$\n",
    "\n",
    "In practice we usually compute the style loss at a set of layers $\\mathcal{L}$ rather than just a single layer $\\ell$; then the total style loss is the sum of style losses at each layer:\n",
    "\n",
    "$$L_s = \\sum_{\\ell \\in \\mathcal{L}} L_s^\\ell$$\n",
    "\n",
    "Begin by implementing the Gram matrix computation below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(features, normalize=True):\n",
    "    \"\"\"\n",
    "    Compute the Gram matrix from features.\n",
    "    \n",
    "    Inputs:\n",
    "    - features: Tensor of shape (1, H, W, C) giving features for\n",
    "      a single image.\n",
    "    - normalize: optional, whether to normalize the Gram matrix\n",
    "        If True, divide the Gram matrix by the number of neurons (H * W * C)\n",
    "    \n",
    "    Returns:\n",
    "    - gram: Tensor of shape (C, C) giving the (optionally normalized)\n",
    "      Gram matrices for the input image.\n",
    "    \"\"\"\n",
    "    shapes = tf.shape(features)\n",
    "    H, W, C = shapes[1], shapes[2], shapes[3]\n",
    "    feats = tf.reshape(features, [H*W, C])\n",
    "    gram = tf.matmul(tf.transpose(feats), feats)\n",
    "    if normalize:\n",
    "        gram /= tf.cast(H*W*C, dtype=tf.float32)\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your Gram matrix code. You should see errors less than 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value features/layer4/fire/e11/weights\n\t [[node features/layer4/fire/e11/weights/read (defined at /home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py:13) ]]\n\nCaused by op 'features/layer4/fire/e11/weights/read', defined at:\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-260843c80395>\", line 11, in <module>\n    model = SqueezeNet(save_path=SAVE_PATH, sess=sess)\n  File \"/home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py\", line 87, in __init__\n    self.layers = self.extract_features(x, reuse=False)\n  File \"/home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py\", line 48, in extract_features\n    x = fire_module(x,128,16,64,64)\n  File \"/home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py\", line 13, in fire_module\n    W = tf.get_variable(\"weights\",shape=[1,1,sp,e11p])\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1479, in get_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1220, in get_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 547, in get_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 499, in _true_getter\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 911, in _get_single_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1557, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 81, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3890, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value features/layer4/fire/e11/weights\n\t [[node features/layer4/fire/e11/weights/read (defined at /home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py:13) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value features/layer4/fire/e11/weights\n\t [[{{node features/layer4/fire/e11/weights/read}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-402476415f89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Maximum error is {:.3f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mgram_matrix_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gm_out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-402476415f89>\u001b[0m in \u001b[0;36mgram_matrix_test\u001b[0;34m(correct)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgram_matrix_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mgram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgram_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mstudent_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstyle_img_test\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrel_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Maximum error is {:.3f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value features/layer4/fire/e11/weights\n\t [[node features/layer4/fire/e11/weights/read (defined at /home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py:13) ]]\n\nCaused by op 'features/layer4/fire/e11/weights/read', defined at:\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-260843c80395>\", line 11, in <module>\n    model = SqueezeNet(save_path=SAVE_PATH, sess=sess)\n  File \"/home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py\", line 87, in __init__\n    self.layers = self.extract_features(x, reuse=False)\n  File \"/home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py\", line 48, in extract_features\n    x = fire_module(x,128,16,64,64)\n  File \"/home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py\", line 13, in fire_module\n    W = tf.get_variable(\"weights\",shape=[1,1,sp,e11p])\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1479, in get_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1220, in get_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 547, in get_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 499, in _true_getter\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 911, in _get_single_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1557, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 81, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3890, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value features/layer4/fire/e11/weights\n\t [[node features/layer4/fire/e11/weights/read (defined at /home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py:13) ]]\n"
     ]
    }
   ],
   "source": [
    "def gram_matrix_test(correct):\n",
    "    gram = gram_matrix(model.extract_features()[5])\n",
    "    student_output = sess.run(gram, {model.image: style_img_test})\n",
    "    error = rel_error(correct, student_output)\n",
    "    print('Maximum error is {:.3f}'.format(error))\n",
    "\n",
    "gram_matrix_test(answers['gm_out'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, implement the style loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def style_loss(feats, style_layers, style_targets, style_weights):\n",
    "    \"\"\"\n",
    "    Computes the style loss at a set of layers.\n",
    "    \n",
    "    Inputs:\n",
    "    - feats: list of the features at every layer of the current image, as produced by\n",
    "      the extract_features function.\n",
    "    - style_layers: List of layer indices into feats giving the layers to include in the\n",
    "      style loss.\n",
    "    - style_targets: List of the same length as style_layers, where style_targets[i] is\n",
    "      a Tensor giving the Gram matrix the source style image computed at\n",
    "      layer style_layers[i].\n",
    "    - style_weights: List of the same length as style_layers, where style_weights[i]\n",
    "      is a scalar giving the weight for the style loss at layer style_layers[i].\n",
    "      \n",
    "    Returns:\n",
    "    - style_loss: A Tensor contataining the scalar style loss.\n",
    "    \"\"\"\n",
    "    # Hint: you can do this with one for loop over the style layers, and should\n",
    "    # not be very much code (~5 lines). You will need to use your gram_matrix function.\n",
    "    style_loss = 0\n",
    "    for i in range(len(style_layers)):\n",
    "        Gram = gram_matrix(feats[style_layers[i]])\n",
    "        style_loss += style_weights[i] * tf.reduce_sum(tf.square(G - style_targets[i]))\n",
    "    return style_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your style loss implementation. The error should be less than 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value features/layer7/fire/e11/weights\n\t [[node features/layer7/fire/e11/weights/read (defined at /home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py:13) ]]\n\nCaused by op 'features/layer7/fire/e11/weights/read', defined at:\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-260843c80395>\", line 11, in <module>\n    model = SqueezeNet(save_path=SAVE_PATH, sess=sess)\n  File \"/home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py\", line 87, in __init__\n    self.layers = self.extract_features(x, reuse=False)\n  File \"/home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py\", line 57, in extract_features\n    x = fire_module(x,256,32,128,128)\n  File \"/home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py\", line 13, in fire_module\n    W = tf.get_variable(\"weights\",shape=[1,1,sp,e11p])\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1479, in get_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1220, in get_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 547, in get_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 499, in _true_getter\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 911, in _get_single_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1557, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 81, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3890, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value features/layer7/fire/e11/weights\n\t [[node features/layer7/fire/e11/weights/read (defined at /home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py:13) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value features/layer7/fire/e11/weights\n\t [[{{node features/layer7/fire/e11/weights/read}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-37a601c39f3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error is {:.3f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mstyle_loss_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sl_out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-37a601c39f3d>\u001b[0m in \u001b[0;36mstyle_loss_test\u001b[0;34m(correct)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mstyle_target_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgram_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     style_targets = sess.run(style_target_vars,\n\u001b[0;32m---> 10\u001b[0;31m                              {model.image: style_img_test})\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0ms_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstyle_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value features/layer7/fire/e11/weights\n\t [[node features/layer7/fire/e11/weights/read (defined at /home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py:13) ]]\n\nCaused by op 'features/layer7/fire/e11/weights/read', defined at:\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-260843c80395>\", line 11, in <module>\n    model = SqueezeNet(save_path=SAVE_PATH, sess=sess)\n  File \"/home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py\", line 87, in __init__\n    self.layers = self.extract_features(x, reuse=False)\n  File \"/home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py\", line 57, in extract_features\n    x = fire_module(x,256,32,128,128)\n  File \"/home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py\", line 13, in fire_module\n    W = tf.get_variable(\"weights\",shape=[1,1,sp,e11p])\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1479, in get_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1220, in get_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 547, in get_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 499, in _true_getter\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 911, in _get_single_variable\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1557, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 81, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3890, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/fhz/miniconda3/envs/deeplearning/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value features/layer7/fire/e11/weights\n\t [[node features/layer7/fire/e11/weights/read (defined at /home/fhz/Desktop/Stanford/CS231n/Assignment/Assignment 3/cs231n/classifiers/squeezenet.py:13) ]]\n"
     ]
    }
   ],
   "source": [
    "def style_loss_test(correct):\n",
    "    style_layers = [1, 4, 6, 7]\n",
    "    style_weights = [300000, 1000, 15, 3]\n",
    "    \n",
    "    feats = model.extract_features()\n",
    "    style_target_vars = []\n",
    "    for idx in style_layers:\n",
    "        style_target_vars.append(gram_matrix(feats[idx]))\n",
    "    style_targets = sess.run(style_target_vars,\n",
    "                             {model.image: style_img_test})\n",
    "                             \n",
    "    s_loss = style_loss(feats, style_layers, style_targets, style_weights)\n",
    "    student_output = sess.run(s_loss, {model.image: content_img_test})\n",
    "    error = rel_error(correct, student_output)\n",
    "    print('Error is {:.3f}'.format(error))\n",
    "\n",
    "style_loss_test(answers['sl_out'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total-variation regularization\n",
    "It turns out that it's helpful to also encourage smoothness in the image. We can do this by adding another term to our loss that penalizes wiggles or \"total variation\" in the pixel values. \n",
    "\n",
    "You can compute the \"total variation\" as the sum of the squares of differences in the pixel values for all pairs of pixels that are next to each other (horizontally or vertically). Here we sum the total-variation regualarization for each of the 3 input channels (RGB), and weight the total summed loss by the total variation weight, $w_t$:\n",
    "\n",
    "$L_{tv} = w_t \\times \\sum_{c=1}^3\\sum_{i=1}^{H-1} \\sum_{j=1}^{W-1} \\left( (x_{i,j+1, c} - x_{i,j,c})^2 + (x_{i+1, j,c} - x_{i,j,c})^2  \\right)$\n",
    "\n",
    "In the next cell, fill in the definition for the TV loss term. To receive full credit, your implementation should not have any loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tv_loss(img, tv_weight):\n",
    "    \"\"\"\n",
    "    Compute total variation loss.\n",
    "    \n",
    "    Inputs:\n",
    "    - img: Tensor of shape (1, H, W, 3) holding an input image.\n",
    "    - tv_weight: Scalar giving the weight w_t to use for the TV loss.\n",
    "    \n",
    "    Returns:\n",
    "    - loss: Tensor holding a scalar giving the total variation loss\n",
    "      for img weighted by tv_weight.\n",
    "    \"\"\"\n",
    "    # Your implementation should be vectorized and not require any loops!\n",
    "    shapes = tf.shape(img)\n",
    "    H, W, C = shapes[1], shapes[2], shapes[3]\n",
    "    wid_diff = img[:, :, :W-1, :] - img[:, :, 1:, :]\n",
    "    hei_diff = img[:, :H-1, :, :] - img[:, 1:, :, :]\n",
    "    total_val_loss = tv_weight * (tf.reduce_sum(tf.square(wid_diff)) + tf.reduce_sum(tf.square(hei_diff)))\n",
    "    return total_val_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your TV loss implementation. Error should be less  than 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error is 0.000\n"
     ]
    }
   ],
   "source": [
    "def tv_loss_test(correct):\n",
    "    tv_weight = 2e-2\n",
    "    t_loss = tv_loss(model.image, tv_weight)\n",
    "    student_output = sess.run(t_loss, {model.image: content_img_test})\n",
    "    error = rel_error(correct, student_output)\n",
    "    print('Error is {:.3f}'.format(error))\n",
    "\n",
    "tv_loss_test(answers['tv_out'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets put it all together and make some beautiful images! The `style_transfer` function below combines all the losses you coded up above and optimizes for an image that minimizes the total loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def style_transfer(content_image, style_image, image_size, style_size, content_layer, content_weight,\n",
    "                   style_layers, style_weights, tv_weight, init_random = False):\n",
    "    \"\"\"Run style transfer!\n",
    "    \n",
    "    Inputs:\n",
    "    - content_image: filename of content image\n",
    "    - style_image: filename of style image\n",
    "    - image_size: size of smallest image dimension (used for content loss and generated image)\n",
    "    - style_size: size of smallest style image dimension\n",
    "    - content_layer: layer to use for content loss\n",
    "    - content_weight: weighting on content loss\n",
    "    - style_layers: list of layers to use for style loss\n",
    "    - style_weights: list of weights to use for each layer in style_layers\n",
    "    - tv_weight: weight of total variation regularization term\n",
    "    - init_random: initialize the starting image to uniform random noise\n",
    "    \"\"\"\n",
    "    # Extract features from the content image\n",
    "    content_img = preprocess_image(load_image(content_image, size=image_size))\n",
    "    feats = model.extract_features(model.image)\n",
    "    content_target = sess.run(feats[content_layer],\n",
    "                              {model.image: content_img[None]})\n",
    "\n",
    "    # Extract features from the style image\n",
    "    style_img = preprocess_image(load_image(style_image, size=style_size))\n",
    "    style_feat_vars = [feats[idx] for idx in style_layers]\n",
    "    style_target_vars = []\n",
    "    # Compute list of TensorFlow Gram matrices\n",
    "    for style_feat_var in style_feat_vars:\n",
    "        style_target_vars.append(gram_matrix(style_feat_var))\n",
    "    # Compute list of NumPy Gram matrices by evaluating the TensorFlow graph on the style image\n",
    "    style_targets = sess.run(style_target_vars, {model.image: style_img[None]})\n",
    "\n",
    "    # Initialize generated image to content image\n",
    "    \n",
    "    if init_random:\n",
    "        img_var = tf.Variable(tf.random_uniform(content_img[None].shape, 0, 1), name=\"image\")\n",
    "    else:\n",
    "        img_var = tf.Variable(content_img[None], name=\"image\")\n",
    "\n",
    "    # Extract features on generated image\n",
    "    feats = model.extract_features(img_var)\n",
    "    # Compute loss\n",
    "    c_loss = content_loss(content_weight, feats[content_layer], content_target)\n",
    "    s_loss = style_loss(feats, style_layers, style_targets, style_weights)\n",
    "    t_loss = tv_loss(img_var, tv_weight)\n",
    "    loss = c_loss + s_loss + t_loss\n",
    "    \n",
    "    # Set up optimization hyperparameters\n",
    "    initial_lr = 3.0\n",
    "    decayed_lr = 0.1\n",
    "    decay_lr_at = 180\n",
    "    max_iter = 200\n",
    "\n",
    "    # Create and initialize the Adam optimizer\n",
    "    lr_var = tf.Variable(initial_lr, name=\"lr\")\n",
    "    # Create train_op that updates the generated image when run\n",
    "    with tf.variable_scope(\"optimizer\") as opt_scope:\n",
    "        train_op = tf.train.AdamOptimizer(lr_var).minimize(loss, var_list=[img_var])\n",
    "    # Initialize the generated image and optimization variables\n",
    "    opt_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=opt_scope.name)\n",
    "    sess.run(tf.variables_initializer([lr_var, img_var] + opt_vars))\n",
    "    # Create an op that will clamp the image values when run\n",
    "    clamp_image_op = tf.assign(img_var, tf.clip_by_value(img_var, -1.5, 1.5))\n",
    "    \n",
    "    f, axarr = plt.subplots(1,2)\n",
    "    axarr[0].axis('off')\n",
    "    axarr[1].axis('off')\n",
    "    axarr[0].set_title('Content Source Img.')\n",
    "    axarr[1].set_title('Style Source Img.')\n",
    "    axarr[0].imshow(deprocess_image(content_img))\n",
    "    axarr[1].imshow(deprocess_image(style_img))\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    \n",
    "    # Hardcoded handcrafted \n",
    "    for t in range(max_iter):\n",
    "        # Take an optimization step to update img_var\n",
    "        sess.run(train_op)\n",
    "        if t < decay_lr_at:\n",
    "            sess.run(clamp_image_op)\n",
    "        if t == decay_lr_at:\n",
    "            sess.run(tf.assign(lr_var, decayed_lr))\n",
    "        if t % 100 == 0:\n",
    "            print('Iteration {}'.format(t))\n",
    "            img = sess.run(img_var)\n",
    "            plt.imshow(deprocess_image(img[0], rescale=True))\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "    print('Iteration {}'.format(t))\n",
    "    img = sess.run(img_var)        \n",
    "    plt.imshow(deprocess_image(img[0], rescale=True))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some pretty pictures!\n",
    "\n",
    "Try out `style_transfer` on the three different parameter sets below. Make sure to run all three cells. Feel free to add your own, but make sure to include the results of style transfer on the third parameter set (starry night) in your submitted notebook.\n",
    "\n",
    "* The `content_image` is the filename of content image.\n",
    "* The `style_image` is the filename of style image.\n",
    "* The `image_size` is the size of smallest image dimension of the content image (used for content loss and generated image).\n",
    "* The `style_size` is the size of smallest style image dimension.\n",
    "* The `content_layer` specifies which layer to use for content loss.\n",
    "* The `content_weight` gives weighting on content loss in the overall loss function. Increasing the value of this parameter will make the final image look more realistic (closer to the original content).\n",
    "* `style_layers` specifies a list of which layers to use for style loss. \n",
    "* `style_weights` specifies a list of weights to use for each layer in style_layers (each of which will contribute a term to the overall style loss). We generally use higher weights for the earlier style layers because they describe more local/smaller scale features, which are more important to texture than features over larger receptive fields. In general, increasing these weights will make the resulting image look less like the original content and more distorted towards the appearance of the style image.\n",
    "* `tv_weight` specifies the weighting of total variation regularization in the overall loss function. Increasing this value makes the resulting image look smoother and less jagged, at the cost of lower fidelity to style and content. \n",
    "\n",
    "Below the next three cells of code (in which you shouldn't change the hyperparameters), feel free to copy and paste the parameters to play around them and see how the resulting image changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composition VII + Tubingen\n",
    "params1 = {\n",
    "    'content_image' : 'styles/tubingen.jpg',\n",
    "    'style_image' : 'styles/composition_vii.jpg',\n",
    "    'image_size' : 192,\n",
    "    'style_size' : 512,\n",
    "    'content_layer' : 3,\n",
    "    'content_weight' : 5e-2, \n",
    "    'style_layers' : (1, 4, 6, 7),\n",
    "    'style_weights' : (20000, 500, 12, 1),\n",
    "    'tv_weight' : 5e-2\n",
    "}\n",
    "\n",
    "style_transfer(**params1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scream + Tubingen\n",
    "params2 = {\n",
    "    'content_image':'styles/tubingen.jpg',\n",
    "    'style_image':'styles/the_scream.jpg',\n",
    "    'image_size':192,\n",
    "    'style_size':224,\n",
    "    'content_layer':3,\n",
    "    'content_weight':3e-2,\n",
    "    'style_layers':[1, 4, 6, 7],\n",
    "    'style_weights':[200000, 800, 12, 1],\n",
    "    'tv_weight':2e-2\n",
    "}\n",
    "\n",
    "style_transfer(**params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starry Night + Tubingen\n",
    "params3 = {\n",
    "    'content_image' : 'styles/tubingen.jpg',\n",
    "    'style_image' : 'styles/starry_night.jpg',\n",
    "    'image_size' : 192,\n",
    "    'style_size' : 192,\n",
    "    'content_layer' : 3,\n",
    "    'content_weight' : 6e-2,\n",
    "    'style_layers' : [1, 4, 6, 7],\n",
    "    'style_weights' : [300000, 1000, 15, 3],\n",
    "    'tv_weight' : 2e-2\n",
    "}\n",
    "\n",
    "style_transfer(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Inversion\n",
    "\n",
    "The code you've written can do another cool thing. In an attempt to understand the types of features that convolutional networks learn to recognize, a recent paper [1] attempts to reconstruct an image from its feature representation. We can easily implement this idea using image gradients from the pretrained network, which is exactly what we did above (but with two different feature representations).\n",
    "\n",
    "Now, if you set the style weights to all be 0 and initialize the starting image to random noise instead of the content source image, you'll reconstruct an image from the feature representation of the content source image. You're starting with total noise, but you should end up with something that looks quite a bit like your original image.\n",
    "\n",
    "(Similarly, you could do \"texture synthesis\" from scratch if you set the content weight to 0 and initialize the starting image to random noise, but we won't ask you to do that here.) \n",
    "\n",
    "[1] Aravindh Mahendran, Andrea Vedaldi, \"Understanding Deep Image Representations by Inverting them\", CVPR 2015\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Inversion -- Starry Night + Tubingen\n",
    "params_inv = {\n",
    "    'content_image' : 'styles/tubingen.jpg',\n",
    "    'style_image' : 'styles/starry_night.jpg',\n",
    "    'image_size' : 192,\n",
    "    'style_size' : 192,\n",
    "    'content_layer' : 3,\n",
    "    'content_weight' : 6e-2,\n",
    "    'style_layers' : [1, 4, 6, 7],\n",
    "    'style_weights' : [0, 0, 0, 0], # we discard any contributions from style to the loss\n",
    "    'tv_weight' : 2e-2,\n",
    "    'init_random': True # we want to initialize our image to be random\n",
    "}\n",
    "\n",
    "style_transfer(**params_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
